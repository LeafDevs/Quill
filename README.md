# Quill - AI Development Assistant

A beautiful terminal-based AI assistant for developers, built with Rust and designed to work seamlessly with Ollama models.

## Features

- ğŸ¨ **Beautiful TUI Interface** - Aqua-pink-aqua gradient title with modern terminal UI
- ğŸ¤– **Ollama Integration** - Connect to your local Ollama instance
- ğŸ“ **Model Selection** - Browse and select from available models using arrow keys
- ğŸ’¬ **Real-time Chat** - Interactive conversation with AI models
- âš¡ **Fast & Responsive** - Built in Rust for optimal performance
- ğŸ”§ **Developer Friendly** - Perfect for coding assistance and development tasks

## Screenshots

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Q u i l l                           â”‚
â”‚                  AI Development Assistant                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Select Model    â”‚ â”‚ Model Info                              â”‚
â”‚ (â†‘/â†“)          â”‚ â”‚                                         â”‚
â”‚                 â”‚ â”‚ Model: llama2:7b                        â”‚
â”‚ > llama2:7b     â”‚ â”‚ Size: 3.8 GB                            â”‚
â”‚   codellama:7b  â”‚ â”‚ Modified: 2024-01-15 14:30             â”‚
â”‚   mistral:7b    â”‚ â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat                                                       â”‚
â”‚                                                             â”‚
â”‚ [USER] 14:25                                                â”‚
â”‚   How do I implement a binary search tree in Rust?         â”‚
â”‚                                                             â”‚
â”‚ [ASSISTANT] 14:25                                           â”‚
â”‚   Here's how to implement a binary search tree in Rust:    â”‚
â”‚                                                             â”‚
â”‚   ```rust                                                   â”‚
â”‚   #[derive(Debug)]                                          â”‚
â”‚   struct Node<T> {                                          â”‚
â”‚       value: T,                                             â”‚
â”‚       left: Option<Box<Node<T>>>,                          â”‚
â”‚       right: Option<Box<Node<T>>>,                         â”‚
â”‚   }                                                         â”‚
â”‚   ```                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input (Enter to send, Ctrl+C to quit)                      â”‚
â”‚ You: _                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- [Rust](https://rustup.rs/) (latest stable version)
- [Ollama](https://ollama.ai/) installed and running
- At least one Ollama model downloaded

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd quill
```

2. Build the project:
```bash
cargo build --release
```

3. Run Quill:
```bash
cargo run --release
```

## Usage

### Starting Quill

1. Make sure Ollama is running:
```bash
ollama serve
```

2. Launch Quill:
```bash
cargo run --release
```

### Navigation

- **Arrow Keys (â†‘/â†“)**: Navigate through available models
- **Type**: Enter your message in the input area
- **Enter**: Send message to the selected AI model
- **Ctrl+C** or **q**: Quit the application

### Features

- **Model Selection**: Use arrow keys to browse and select from your available Ollama models
- **Real-time Chat**: Have conversations with AI models in real-time
- **Message History**: View your conversation history in the chat area
- **Error Handling**: Clear error messages if something goes wrong
- **Loading States**: Visual feedback when the AI is processing your request

## Configuration

Quill connects to Ollama on the default port `11434`. If you're running Ollama on a different port, you can modify the `base_url` in `src/ollama.rs`.

## Development

### Project Structure

```
src/
â”œâ”€â”€ main.rs      # Application entry point
â”œâ”€â”€ app.rs       # Application state and logic
â”œâ”€â”€ ollama.rs    # Ollama API client
â”œâ”€â”€ ui.rs        # Terminal UI components
â””â”€â”€ utils.rs     # Utility functions
```

### Building for Development

```bash
cargo build
```

### Running Tests

```bash
cargo test
```

## Troubleshooting

### Common Issues

1. **"Failed to fetch models"**: Make sure Ollama is running (`ollama serve`)
2. **"Failed to get response"**: Check if the selected model is downloaded
3. **Terminal display issues**: Ensure your terminal supports UTF-8 and colors

### Getting Help

If you encounter any issues:

1. Check that Ollama is running and accessible
2. Verify you have at least one model downloaded (`ollama list`)
3. Ensure your terminal supports the required features
4. Check the error messages displayed in the application

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Built with [tui-rs](https://github.com/fdehau/tui-rs) for the terminal UI
- Powered by [Ollama](https://ollama.ai/) for AI model access
- Inspired by modern terminal applications and AI development tools 